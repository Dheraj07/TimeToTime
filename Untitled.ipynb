{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d173cfe-4f10-4227-9571-909b28d86d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'templates' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create folder 'templates' in the current working directory\n",
    "os.makedirs(\"templates\", exist_ok=True)\n",
    "\n",
    "print(\"Folder 'templates' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e804292d-123f-4761-b5f3-c8b06444f751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HTML file created: templates/index2.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "html_content=\"\"\"\n",
    "<!doctype html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>Predict Price at DateTime</title>\n",
    "  <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "  <style>\n",
    "    body { padding: 30px; background: #f7f9fb; }\n",
    "    .card { max-width: 800px; margin: 0 auto; }\n",
    "    .mono { font-family: monospace; }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <div class=\"card shadow-sm\">\n",
    "    <div class=\"card-body\">\n",
    "      <h4 class=\"card-title\">Predict stock price at a specific datetime</h4>\n",
    "      <p class=\"text-muted\">Enter ticker and a date+time (format: YYYY-MM-DD HH:MM). Uses last 30 days for training.</p>\n",
    "\n",
    "      <form method=\"POST\" action=\"/predict\" class=\"row g-2 align-items-center mb-3\">\n",
    "        <div class=\"col-md-5\">\n",
    "          <input type=\"text\" name=\"stock\" class=\"form-control\" placeholder=\"Ticker (e.g. AAPL)\" required>\n",
    "        </div>\n",
    "        <div class=\"col-md-5\">\n",
    "          <input type=\"text\" name=\"datetime\" class=\"form-control\" placeholder=\"Datetime (YYYY-MM-DD HH:MM)\" required>\n",
    "        </div>\n",
    "        <div class=\"col-md-2\">\n",
    "          <button class=\"btn btn-primary w-100\">Predict</button>\n",
    "        </div>\n",
    "      </form>\n",
    "\n",
    "      {% if error %}\n",
    "        <div class=\"alert alert-danger\">{{ error }}</div>\n",
    "      {% endif %}\n",
    "\n",
    "      {% if finbert_msg %}\n",
    "        <div class=\"alert alert-warning\">{{ finbert_msg }}</div>\n",
    "      {% endif %}\n",
    "\n",
    "      {% if prophet_price %}\n",
    "        <div class=\"mt-3\">\n",
    "          <h5>Results for {{ ticker }} at {{ input_datetime }}</h5>\n",
    "          <ul class=\"list-group\">\n",
    "            <li class=\"list-group-item\"><b>Prophet (15-min freq) prediction:</b> <span class=\"mono\">${{ prophet_price }}</span></li>\n",
    "            <li class=\"list-group-item\"><b>XGBoost prediction:</b> <span class=\"mono\">${{ xgb_price }}</span></li>\n",
    "            <li class=\"list-group-item\"><b>Latest sentiment (for that date):</b> {{ sentiment_label }}</li>\n",
    "          </ul>\n",
    "        </div>\n",
    "      {% endif %}\n",
    "    </div>\n",
    "  </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# Write to templates/index.html\n",
    "with open(\"templates/index2.html\", \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(\"✅ HTML file created: templates/index2.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b4d02a-1892-4173-a24e-9094a091ee04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Finbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70c07bf-d1c6-4bbc-9ea3-3d12b53bc647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start_date, end=end_date, interval=\"15m\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:178: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged['sentiment_score'] = merged['sentiment_score'].fillna(method='ffill').fillna(0.0)\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:179: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged['label'] = merged['label'].fillna(method='ffill').fillna(\"NEUTRAL\")\n",
      "16:04:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:04:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:205: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  future_index = pd.date_range(start=last_hist + pd.Timedelta(minutes=15), end=target_ts, freq=freq)\n",
      "127.0.0.1 - - [01/Nov/2025 16:04:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start_date, end=end_date, interval=\"15m\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:178: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged['sentiment_score'] = merged['sentiment_score'].fillna(method='ffill').fillna(0.0)\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:179: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged['label'] = merged['label'].fillna(method='ffill').fillna(\"NEUTRAL\")\n",
      "16:06:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:06:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/1694904456.py:205: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  future_index = pd.date_range(start=last_hist + pd.Timedelta(minutes=15), end=target_ts, freq=freq)\n",
      "127.0.0.1 - - [01/Nov/2025 16:06:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "os.environ.setdefault(\"NEWS_API_KEY\", \"1b2519a9542b4c108e5678753641c6f8\")\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "\n",
    "# ----------------- Load FinBERT once -----------------\n",
    "finbert_pipeline = None\n",
    "finbert_load_error = None\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "    finbert_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "except Exception as e:\n",
    "    finbert_pipeline = None\n",
    "    finbert_load_error = str(e)\n",
    "\n",
    "# ----------------- Flask -----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template(\"index2.html\")\n",
    "\n",
    "def fetch_news_texts(query, from_date, to_date, api_key, page_size=100):\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"from\": from_date,\n",
    "        \"to\": to_date,\n",
    "        \"language\": \"en\",\n",
    "        \"sortBy\": \"relevancy\",\n",
    "        \"pageSize\": page_size,\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=20)\n",
    "    data = r.json()\n",
    "    articles = data.get(\"articles\", [])\n",
    "    texts = []\n",
    "    for art in articles:\n",
    "        title = art.get(\"title\") or \"\"\n",
    "        desc = art.get(\"description\") or \"\"\n",
    "        text = (title + \". \" + desc).strip()\n",
    "        pub = art.get(\"publishedAt\", \"\")\n",
    "        pub_date = pub[:10] if pub else \"\"\n",
    "        if text:\n",
    "            texts.append((text, pub_date))\n",
    "    return texts\n",
    "\n",
    "def get_daily_sentiment_from_texts(text_date_pairs):\n",
    "    if not text_date_pairs:\n",
    "        return pd.DataFrame(columns=[\"date\", \"sentiment_score\", \"label\"])\n",
    "\n",
    "    if finbert_pipeline is None:\n",
    "        rows = []\n",
    "        for text, date_str in text_date_pairs:\n",
    "            if date_str:\n",
    "                rows.append({\"date\": pd.to_datetime(date_str).date(), \"score\": 0.0, \"label\": \"NEUTRAL\"})\n",
    "        if not rows:\n",
    "            return pd.DataFrame(columns=[\"date\",\"sentiment_score\",\"label\"])\n",
    "        df = pd.DataFrame(rows)\n",
    "        daily = df.groupby(\"date\", as_index=False)[\"score\"].mean().rename(columns={\"score\":\"sentiment_score\"})\n",
    "        daily[\"label\"] = \"NEUTRAL\"\n",
    "        return daily\n",
    "\n",
    "    texts = [t for t, d in text_date_pairs]\n",
    "    results = finbert_pipeline(texts, batch_size=16, truncation=True)\n",
    "\n",
    "    records = []\n",
    "    for (text, date_str), res in zip(text_date_pairs, results):\n",
    "        if not date_str:\n",
    "            continue\n",
    "        try:\n",
    "            d = pd.to_datetime(date_str).date()\n",
    "        except:\n",
    "            continue\n",
    "        score = float(res.get(\"score\", 0.0))\n",
    "        label = res.get(\"label\", \"\").upper()\n",
    "        records.append({\"date\": d, \"score\": score, \"label\": label})\n",
    "\n",
    "    if not records:\n",
    "        return pd.DataFrame(columns=[\"date\",\"sentiment_score\",\"label\"])\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    daily_score = df.groupby(\"date\", as_index=False)[\"score\"].mean().rename(columns={\"score\":\"sentiment_score\"})\n",
    "    label_df = df.groupby(\"date\")[\"label\"].agg(lambda x: x.mode().iat[0] if not x.mode().empty else \"NEUTRAL\").reset_index()\n",
    "    merged = pd.merge(daily_score, label_df, on=\"date\", how=\"left\")\n",
    "    return merged\n",
    "\n",
    "def fetch_intraday_15m(ticker, start_date, end_date):\n",
    "    yf_start = str(start_date)\n",
    "    yf_end = str(end_date + timedelta(days=1))\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, interval=\"15m\")\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df = df.reset_index()\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "    if 'Datetime' in df.columns:\n",
    "        df.rename(columns={'Datetime':'datetime'}, inplace=True)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['Datetime'] if 'Datetime' in df.columns else df['datetime']).dt.date\n",
    "    if 'Close' not in df.columns:\n",
    "        close_cols = [c for c in df.columns if c.lower().endswith('close')]\n",
    "        if close_cols:\n",
    "            df.rename(columns={close_cols[0]:'Close'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if finbert_load_error:\n",
    "        finbert_msg = f\"FinBERT load error at startup: {finbert_load_error}. Running with neutral sentiment.\"\n",
    "    else:\n",
    "        finbert_msg = None\n",
    "\n",
    "    user_ticker = request.form.get('stock', '').strip()\n",
    "    user_dt_str = request.form.get('datetime', '').strip()\n",
    "\n",
    "    if not user_ticker or not user_dt_str:\n",
    "        return render_template(\"index.html\", error=\"Please provide both stock ticker and date-time (YYYY-MM-DD HH:MM).\")\n",
    "\n",
    "    try:\n",
    "        requested_dt = pd.to_datetime(user_dt_str).tz_localize(None)\n",
    "    except Exception as e:\n",
    "        return render_template(\"index.html\", error=f\"Could not parse datetime: {e}. Use format YYYY-MM-DD HH:MM\")\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    past = today - timedelta(days=30)\n",
    "    start_date = past\n",
    "    end_date = today\n",
    "\n",
    "    try:\n",
    "        query = f'(\"{user_ticker}\" OR \"{user_ticker.upper()}\") AND (stock OR shares OR earnings OR market OR price)'\n",
    "        texts = fetch_news_texts(query, from_date=str(start_date), to_date=str(end_date), api_key=NEWS_API_KEY, page_size=100)\n",
    "        daily_sent = get_daily_sentiment_from_texts(texts)\n",
    "\n",
    "        if daily_sent.empty:\n",
    "            daily_sent = pd.DataFrame({\n",
    "                \"date\": [d for d in pd.date_range(start=start_date, end=end_date).date],\n",
    "                \"sentiment_score\": [0.0]*((end_date-start_date).days+1),\n",
    "                \"label\": [\"NEUTRAL\"]*((end_date-start_date).days+1)\n",
    "            })\n",
    "\n",
    "        stock_df = fetch_intraday_15m(user_ticker, start_date, end_date)\n",
    "        if stock_df.empty:\n",
    "            return render_template(\"index2.html\", error=f\"No intraday 15-min data found for {user_ticker} in the last 30 days (yfinance returned empty).\")\n",
    "\n",
    "        if 'Datetime' in stock_df.columns:\n",
    "            stock_df['datetime'] = pd.to_datetime(stock_df['Datetime']).dt.tz_localize(None)\n",
    "        else:\n",
    "            if 'datetime' not in stock_df.columns:\n",
    "                stock_df['datetime'] = pd.to_datetime(stock_df.iloc[:,0]).dt.tz_localize(None)\n",
    "            else:\n",
    "                stock_df['datetime'] = pd.to_datetime(stock_df['datetime']).dt.tz_localize(None)\n",
    "\n",
    "        if 'Close' not in stock_df.columns:\n",
    "            close_candidates = [c for c in stock_df.columns if c.lower().endswith('close')]\n",
    "            if close_candidates:\n",
    "                stock_df.rename(columns={close_candidates[0]:'Close'}, inplace=True)\n",
    "            else:\n",
    "                return render_template(\"index2.html\", error=\"Could not find Close price column in stock data.\")\n",
    "\n",
    "        stock_df['date'] = stock_df['datetime'].dt.date\n",
    "        daily_sent['date'] = pd.to_datetime(daily_sent['date']).dt.date\n",
    "        merged = pd.merge(stock_df, daily_sent[['date','sentiment_score','label']], on='date', how='left')\n",
    "        merged['sentiment_score'] = merged['sentiment_score'].fillna(method='ffill').fillna(0.0)\n",
    "        merged['label'] = merged['label'].fillna(method='ffill').fillna(\"NEUTRAL\")\n",
    "\n",
    "        # Prophet\n",
    "        prophet_df = merged[['datetime','Close','sentiment_score']].rename(columns={'datetime':'ds','Close':'y'}).dropna()\n",
    "        prophet_df['ds'] = pd.to_datetime(prophet_df['ds']).dt.tz_localize(None)\n",
    "\n",
    "        m = Prophet()\n",
    "        m.add_regressor('sentiment_score')\n",
    "        m.fit(prophet_df)\n",
    "\n",
    "        last_hist = prophet_df['ds'].max()\n",
    "        target_ts = pd.to_datetime(requested_dt).tz_localize(None)\n",
    "\n",
    "        if target_ts <= last_hist:\n",
    "            target_date = target_ts.date()\n",
    "            sent_row = daily_sent[daily_sent['date'] == target_date]\n",
    "            if not sent_row.empty:\n",
    "                target_sent = float(sent_row['sentiment_score'].iloc[0])\n",
    "            else:\n",
    "                target_sent = float(daily_sent['sentiment_score'].iloc[-1])\n",
    "            df_for_pred = pd.DataFrame({'ds':[target_ts], 'sentiment_score':[target_sent]})\n",
    "            df_for_pred['ds'] = df_for_pred['ds'].dt.tz_localize(None)\n",
    "            pred = m.predict(df_for_pred)\n",
    "            prophet_price = float(pred['yhat'].iloc[0])\n",
    "        else:\n",
    "            freq = '15T'\n",
    "            future_index = pd.date_range(start=last_hist + pd.Timedelta(minutes=15), end=target_ts, freq=freq)\n",
    "            future_df = pd.DataFrame({'ds': future_index})\n",
    "            def get_sent_for_ts(ts):\n",
    "                d = ts.date()\n",
    "                row = daily_sent[daily_sent['date'] == d]\n",
    "                if not row.empty:\n",
    "                    return float(row['sentiment_score'].iloc[0])\n",
    "                else:\n",
    "                    return float(daily_sent['sentiment_score'].iloc[-1])\n",
    "            future_df['sentiment_score'] = future_df['ds'].apply(get_sent_for_ts)\n",
    "            future_df['ds'] = future_df['ds'].dt.tz_localize(None)\n",
    "            pred_future = m.predict(future_df)\n",
    "            prophet_price = float(pred_future[pred_future['ds'] == target_ts]['yhat'].iloc[0]) if target_ts in list(pred_future['ds']) else float(pred_future['yhat'].iloc[-1])\n",
    "\n",
    "        # XGBoost\n",
    "        xdf = merged[['datetime','Close','sentiment_score']].dropna().copy()\n",
    "        xdf['day'] = xdf['datetime'].dt.day\n",
    "        xdf['month'] = xdf['datetime'].dt.month\n",
    "        xdf['year'] = xdf['datetime'].dt.year\n",
    "        xdf['hour'] = xdf['datetime'].dt.hour\n",
    "        xdf['minute'] = xdf['datetime'].dt.minute\n",
    "        xdf['dayofweek'] = xdf['datetime'].dt.dayofweek\n",
    "        X = xdf[['day','month','year','hour','minute','dayofweek','sentiment_score']].values\n",
    "        y = xdf['Close'].values\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        xgb = XGBRegressor(n_estimators=100, verbosity=0)\n",
    "        xgb.fit(X_scaled, y)\n",
    "\n",
    "        req_dt = pd.to_datetime(requested_dt).tz_localize(None)\n",
    "        req_row = {\n",
    "            'day': req_dt.day,\n",
    "            'month': req_dt.month,\n",
    "            'year': req_dt.year,\n",
    "            'hour': req_dt.hour,\n",
    "            'minute': req_dt.minute,\n",
    "            'dayofweek': req_dt.dayofweek,\n",
    "        }\n",
    "        sent_row = daily_sent[daily_sent['date'] == req_dt.date()]\n",
    "        if not sent_row.empty:\n",
    "            req_sent = float(sent_row['sentiment_score'].iloc[0])\n",
    "            req_label = sent_row['label'].iloc[0]\n",
    "        else:\n",
    "            req_sent = float(daily_sent['sentiment_score'].iloc[-1])\n",
    "            req_label = daily_sent['label'].iloc[-1]\n",
    "\n",
    "        req_features = np.array([[req_row['day'], req_row['month'], req_row['year'],\n",
    "                                  req_row['hour'], req_row['minute'], req_row['dayofweek'],\n",
    "                                  req_sent]])\n",
    "        req_scaled = scaler.transform(req_features)\n",
    "        xgb_price = float(xgb.predict(req_scaled)[0])\n",
    "\n",
    "        label_display = str(req_label).title() if pd.notna(req_label) else \"Neutral\"\n",
    "\n",
    "        prophet_price_rounded = round(prophet_price, 4)\n",
    "        xgb_price_rounded = round(xgb_price, 4)\n",
    "\n",
    "        return render_template(\"index2.html\",\n",
    "                               ticker=user_ticker.upper(),\n",
    "                               input_datetime=str(requested_dt),\n",
    "                               prophet_price=prophet_price_rounded,\n",
    "                               xgb_price=xgb_price_rounded,\n",
    "                               sentiment_label=label_display,\n",
    "                               finbert_msg=finbert_msg)\n",
    "\n",
    "    except Exception as e:\n",
    "        return render_template(\"index2.html\", error=f\"Error during processing: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b676ff-f4e4-40b1-9a52-b9a101c7b276",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7cc5f5c-bfb8-4012-93fb-8b0d67b9c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [01/Nov/2025 16:23:38] \"GET / HTTP/1.1\" 200 -\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/183620872.py:82: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, start=start_date, end=end_date, interval=\"15m\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/183620872.py:137: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged[\"sentiment_score\"].fillna(0.0, inplace=True)\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/183620872.py:138: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged[\"label\"].fillna(\"NEUTRAL\", inplace=True)\n",
      "16:23:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:23:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_24927/183620872.py:157: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  future_index = pd.date_range(start=last_hist + pd.Timedelta(minutes=15), end=target_ts, freq=freq)\n",
      "127.0.0.1 - - [01/Nov/2025 16:23:50] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "os.environ.setdefault(\"NEWS_API_KEY\", \"1b2519a9542b4c108e5678753641c6f8\")\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "\n",
    "# ----------------- Initialize VADER -----------------\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ----------------- Flask -----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template(\"index2.html\")\n",
    "\n",
    "def fetch_news_texts(query, from_date, to_date, api_key, page_size=100):\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"from\": from_date,\n",
    "        \"to\": to_date,\n",
    "        \"language\": \"en\",\n",
    "        \"sortBy\": \"relevancy\",\n",
    "        \"pageSize\": page_size,\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=20)\n",
    "    data = r.json()\n",
    "    articles = data.get(\"articles\", [])\n",
    "    texts = []\n",
    "    for art in articles:\n",
    "        title = art.get(\"title\") or \"\"\n",
    "        desc = art.get(\"description\") or \"\"\n",
    "        text = (title + \". \" + desc).strip()\n",
    "        pub = art.get(\"publishedAt\", \"\")\n",
    "        pub_date = pub[:10] if pub else \"\"\n",
    "        if text:\n",
    "            texts.append((text, pub_date))\n",
    "    return texts\n",
    "\n",
    "def get_daily_sentiment_from_texts(text_date_pairs):\n",
    "    if not text_date_pairs:\n",
    "        return pd.DataFrame(columns=[\"date\", \"sentiment_score\", \"label\"])\n",
    "\n",
    "    records = []\n",
    "    for text, date_str in text_date_pairs:\n",
    "        if not date_str:\n",
    "            continue\n",
    "        scores = analyzer.polarity_scores(text)\n",
    "        compound = scores[\"compound\"]\n",
    "        if compound >= 0.05:\n",
    "            label = \"POSITIVE\"\n",
    "        elif compound <= -0.05:\n",
    "            label = \"NEGATIVE\"\n",
    "        else:\n",
    "            label = \"NEUTRAL\"\n",
    "        records.append({\"date\": pd.to_datetime(date_str).date(),\n",
    "                        \"score\": compound,\n",
    "                        \"label\": label})\n",
    "\n",
    "    if not records:\n",
    "        return pd.DataFrame(columns=[\"date\", \"sentiment_score\", \"label\"])\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    daily_score = df.groupby(\"date\", as_index=False)[\"score\"].mean().rename(columns={\"score\":\"sentiment_score\"})\n",
    "    label_df = df.groupby(\"date\")[\"label\"].agg(lambda x: x.mode().iat[0] if not x.mode().empty else \"NEUTRAL\").reset_index()\n",
    "    merged = pd.merge(daily_score, label_df, on=\"date\", how=\"left\")\n",
    "    return merged\n",
    "\n",
    "def fetch_intraday_15m(ticker, start_date, end_date):\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, interval=\"15m\")\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df = df.reset_index()\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [col[0] for col in df.columns]\n",
    "    if \"Datetime\" in df.columns:\n",
    "        df.rename(columns={\"Datetime\": \"datetime\"}, inplace=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"datetime\"]).dt.date\n",
    "    if \"Close\" not in df.columns:\n",
    "        close_cols = [c for c in df.columns if c.lower().endswith(\"close\")]\n",
    "        if close_cols:\n",
    "            df.rename(columns={close_cols[0]: \"Close\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    user_ticker = request.form.get(\"stock\", \"\").strip()\n",
    "    user_dt_str = request.form.get(\"datetime\", \"\").strip()\n",
    "\n",
    "    if not user_ticker or not user_dt_str:\n",
    "        return render_template(\"index2.html\", error=\"Please provide both stock ticker and date-time (YYYY-MM-DD HH:MM).\")\n",
    "\n",
    "    try:\n",
    "        requested_dt = pd.to_datetime(user_dt_str).tz_localize(None)\n",
    "    except Exception as e:\n",
    "        return render_template(\"index2.html\", error=f\"Invalid datetime: {e}. Use YYYY-MM-DD HH:MM\")\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    start_date = today - timedelta(days=30)\n",
    "    end_date = today\n",
    "\n",
    "    try:\n",
    "        # 1️⃣ Fetch News + Sentiment\n",
    "        query = f'(\"{user_ticker}\" OR \"{user_ticker.upper()}\") AND (stock OR shares OR earnings OR market OR price)'\n",
    "        texts = fetch_news_texts(query, str(start_date), str(end_date), NEWS_API_KEY)\n",
    "        daily_sent = get_daily_sentiment_from_texts(texts)\n",
    "\n",
    "        if daily_sent.empty:\n",
    "            daily_sent = pd.DataFrame({\n",
    "                \"date\": [d.date() for d in pd.date_range(start=start_date, end=end_date)],\n",
    "                \"sentiment_score\": [0.0]*((end_date - start_date).days + 1),\n",
    "                \"label\": [\"NEUTRAL\"]*((end_date - start_date).days + 1)\n",
    "            })\n",
    "\n",
    "        # 2️⃣ Fetch Stock Data\n",
    "        stock_df = fetch_intraday_15m(user_ticker, start_date, end_date)\n",
    "        if stock_df.empty:\n",
    "            return render_template(\"index2.html\", error=f\"No 15-min data for {user_ticker}\")\n",
    "\n",
    "        stock_df[\"datetime\"] = pd.to_datetime(stock_df[\"datetime\"]).dt.tz_localize(None)\n",
    "        stock_df[\"date\"] = stock_df[\"datetime\"].dt.date\n",
    "\n",
    "        daily_sent[\"date\"] = pd.to_datetime(daily_sent[\"date\"]).dt.date\n",
    "        merged = pd.merge(stock_df, daily_sent, on=\"date\", how=\"left\")\n",
    "        merged[\"sentiment_score\"].fillna(0.0, inplace=True)\n",
    "        merged[\"label\"].fillna(\"NEUTRAL\", inplace=True)\n",
    "\n",
    "        # 3️⃣ Prophet\n",
    "        prophet_df = merged[[\"datetime\", \"Close\", \"sentiment_score\"]].rename(columns={\"datetime\": \"ds\", \"Close\": \"y\"})\n",
    "        m = Prophet()\n",
    "        m.add_regressor(\"sentiment_score\")\n",
    "        m.fit(prophet_df)\n",
    "\n",
    "        target_ts = requested_dt\n",
    "        last_hist = prophet_df[\"ds\"].max()\n",
    "\n",
    "        if target_ts <= last_hist:\n",
    "            sent_val = daily_sent.loc[daily_sent[\"date\"] == target_ts.date(), \"sentiment_score\"]\n",
    "            target_sent = float(sent_val.iloc[0]) if not sent_val.empty else 0.0\n",
    "            df_pred = pd.DataFrame({\"ds\": [target_ts], \"sentiment_score\": [target_sent]})\n",
    "            pred = m.predict(df_pred)\n",
    "            prophet_price = float(pred[\"yhat\"].iloc[0])\n",
    "        else:\n",
    "            freq = \"15T\"\n",
    "            future_index = pd.date_range(start=last_hist + pd.Timedelta(minutes=15), end=target_ts, freq=freq)\n",
    "            future_df = pd.DataFrame({\"ds\": future_index})\n",
    "            future_df[\"sentiment_score\"] = future_df[\"ds\"].dt.date.map(\n",
    "                lambda d: float(daily_sent.loc[daily_sent[\"date\"] == d, \"sentiment_score\"].iloc[0])\n",
    "                if d in list(daily_sent[\"date\"]) else 0.0\n",
    "            )\n",
    "            pred_future = m.predict(future_df)\n",
    "            prophet_price = float(pred_future[pred_future[\"ds\"] == target_ts][\"yhat\"].iloc[0]) \\\n",
    "                            if target_ts in list(pred_future[\"ds\"]) else float(pred_future[\"yhat\"].iloc[-1])\n",
    "\n",
    "        # 4️⃣ XGBoost\n",
    "        xdf = merged[[\"datetime\", \"Close\", \"sentiment_score\"]].dropna().copy()\n",
    "        xdf[\"day\"] = xdf[\"datetime\"].dt.day\n",
    "        xdf[\"month\"] = xdf[\"datetime\"].dt.month\n",
    "        xdf[\"year\"] = xdf[\"datetime\"].dt.year\n",
    "        xdf[\"hour\"] = xdf[\"datetime\"].dt.hour\n",
    "        xdf[\"minute\"] = xdf[\"datetime\"].dt.minute\n",
    "        xdf[\"dayofweek\"] = xdf[\"datetime\"].dt.dayofweek\n",
    "        X = xdf[[\"day\", \"month\", \"year\", \"hour\", \"minute\", \"dayofweek\", \"sentiment_score\"]].values\n",
    "        y = xdf[\"Close\"].values\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        xgb = XGBRegressor(n_estimators=100, verbosity=0)\n",
    "        xgb.fit(X_scaled, y)\n",
    "\n",
    "        req_dt = requested_dt\n",
    "        req_features = np.array([[req_dt.day, req_dt.month, req_dt.year,\n",
    "                                  req_dt.hour, req_dt.minute, req_dt.dayofweek,\n",
    "                                  float(daily_sent.loc[daily_sent[\"date\"] == req_dt.date(), \"sentiment_score\"].iloc[0])\n",
    "                                  if req_dt.date() in list(daily_sent[\"date\"]) else 0.0]])\n",
    "        req_scaled = scaler.transform(req_features)\n",
    "        xgb_price = float(xgb.predict(req_scaled)[0])\n",
    "\n",
    "        req_label = daily_sent.loc[daily_sent[\"date\"] == req_dt.date(), \"label\"]\n",
    "        label_display = req_label.iloc[0].title() if not req_label.empty else \"Neutral\"\n",
    "\n",
    "        return render_template(\"index2.html\",\n",
    "                               ticker=user_ticker.upper(),\n",
    "                               input_datetime=str(requested_dt),\n",
    "                               prophet_price=round(prophet_price, 4),\n",
    "                               xgb_price=round(xgb_price, 4),\n",
    "                               sentiment_label=label_display)\n",
    "\n",
    "    except Exception as e:\n",
    "        return render_template(\"index2.html\", error=f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12367abc-633c-4582-a97c-83d02ac76838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Flask: Installed=3.1.2, Required=2.2.5\n",
      "⚠️ yfinance: Installed=0.2.66, Required=0.2.36\n",
      "⚠️ prophet: Installed=1.1.7, Required=1.1.5\n",
      "⚠️ pandas: Installed=2.3.2, Required=2.2.2\n",
      "⚠️ numpy: Installed=2.3.3, Required=1.26.4\n",
      "⚠️ xgboost: Installed=3.0.5, Required=2.0.3\n",
      "⚠️ scikit-learn: Installed=1.7.2, Required=1.4.1.post1\n",
      "⚠️ gunicorn: Installed=23.0.0, Required=21.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/bd4zk8k14dx6jpth62btf3wc0000gn/T/ipykernel_89083/3604190694.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "required_packages = {\n",
    "    \"Flask\": \"2.2.5\",\n",
    "    \"yfinance\": \"0.2.36\",\n",
    "    \"prophet\": \"1.1.5\",\n",
    "    \"pandas\": \"2.2.2\",\n",
    "    \"numpy\": \"1.26.4\",\n",
    "    \"xgboost\": \"2.0.3\",\n",
    "    \"scikit-learn\": \"1.4.1.post1\",\n",
    "    \"gunicorn\": \"21.2.0\"\n",
    "}\n",
    "\n",
    "for package, required_version in required_packages.items():\n",
    "    try:\n",
    "        installed_version = pkg_resources.get_distribution(package).version\n",
    "        status = \"✅\" if installed_version == required_version else \"⚠️\"\n",
    "        print(f\"{status} {package}: Installed={installed_version}, Required={required_version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"❌ {package}: Not Installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e7e63a2-ed80-4842-957a-5537fecb1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Procfile\", \"w\") as f:\n",
    "    f.write(\"web: gunicorn app:app\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c14352-dc16-4db5-be4d-86696a05e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Flask app has been saved as app.py\n"
     ]
    }
   ],
   "source": [
    "code=\"\"\"\n",
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "os.environ.setdefault(\"NEWS_API_KEY\", \"1b2519a9542b4c108e5678753641c6f8\")\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "\n",
    "# ----------------- Initialize VADER -----------------\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ----------------- Flask -----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template(\"index2.html\")\n",
    "\n",
    "def fetch_news_texts(query, from_date, to_date, api_key, page_size=100):\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"from\": from_date,\n",
    "        \"to\": to_date,\n",
    "        \"language\": \"en\",\n",
    "        \"sortBy\": \"relevancy\",\n",
    "        \"pageSize\": page_size,\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=20)\n",
    "    data = r.json()\n",
    "    articles = data.get(\"articles\", [])\n",
    "    texts = []\n",
    "    for art in articles:\n",
    "        title = art.get(\"title\") or \"\"\n",
    "        desc = art.get(\"description\") or \"\"\n",
    "        text = (title + \". \" + desc).strip()\n",
    "        pub = art.get(\"publishedAt\", \"\")\n",
    "        pub_date = pub[:10] if pub else \"\"\n",
    "        if text:\n",
    "            texts.append((text, pub_date))\n",
    "    return texts\n",
    "\n",
    "def get_daily_sentiment_from_texts(text_date_pairs):\n",
    "    if not text_date_pairs:\n",
    "        return pd.DataFrame(columns=[\"date\", \"sentiment_score\", \"label\"])\n",
    "\n",
    "    records = []\n",
    "    for text, date_str in text_date_pairs:\n",
    "        if not date_str:\n",
    "            continue\n",
    "        scores = analyzer.polarity_scores(text)\n",
    "        compound = scores[\"compound\"]\n",
    "        if compound >= 0.05:\n",
    "            label = \"POSITIVE\"\n",
    "        elif compound <= -0.05:\n",
    "            label = \"NEGATIVE\"\n",
    "        else:\n",
    "            label = \"NEUTRAL\"\n",
    "        records.append({\"date\": pd.to_datetime(date_str).date(),\n",
    "                        \"score\": compound,\n",
    "                        \"label\": label})\n",
    "\n",
    "    if not records:\n",
    "        return pd.DataFrame(columns=[\"date\", \"sentiment_score\", \"label\"])\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    daily_score = df.groupby(\"date\", as_index=False)[\"score\"].mean().rename(columns={\"score\":\"sentiment_score\"})\n",
    "    label_df = df.groupby(\"date\")[\"label\"].agg(lambda x: x.mode().iat[0] if not x.mode().empty else \"NEUTRAL\").reset_index()\n",
    "    merged = pd.merge(daily_score, label_df, on=\"date\", how=\"left\")\n",
    "    return merged\n",
    "\n",
    "def fetch_intraday_15m(ticker, start_date, end_date):\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, interval=\"15m\")\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df = df.reset_index()\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [col[0] for col in df.columns]\n",
    "    if \"Datetime\" in df.columns:\n",
    "        df.rename(columns={\"Datetime\": \"datetime\"}, inplace=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"datetime\"]).dt.date\n",
    "    if \"Close\" not in df.columns:\n",
    "        close_cols = [c for c in df.columns if c.lower().endswith(\"close\")]\n",
    "        if close_cols:\n",
    "            df.rename(columns={close_cols[0]: \"Close\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    user_ticker = request.form.get(\"stock\", \"\").strip()\n",
    "    user_dt_str = request.form.get(\"datetime\", \"\").strip()\n",
    "\n",
    "    if not user_ticker or not user_dt_str:\n",
    "        return render_template(\"index2.html\", error=\"Please provide both stock ticker and date-time (YYYY-MM-DD HH:MM).\")\n",
    "\n",
    "    try:\n",
    "        requested_dt = pd.to_datetime(user_dt_str).tz_localize(None)\n",
    "    except Exception as e:\n",
    "        return render_template(\"index2.html\", error=f\"Invalid datetime: {e}. Use YYYY-MM-DD HH:MM\")\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    start_date = today - timedelta(days=30)\n",
    "    end_date = today\n",
    "\n",
    "    try:\n",
    "        # 1️⃣ Fetch News + Sentiment\n",
    "        query = f'(\"{user_ticker}\" OR \"{user_ticker.upper()}\") AND (stock OR shares OR earnings OR market OR price)'\n",
    "        texts = fetch_news_texts(query, str(start_date), str(end_date), NEWS_API_KEY)\n",
    "        daily_sent = get_daily_sentiment_from_texts(texts)\n",
    "\n",
    "        if daily_sent.empty:\n",
    "            daily_sent = pd.DataFrame({\n",
    "                \"date\": [d.date() for d in pd.date_range(start=start_date, end=end_date)],\n",
    "                \"sentiment_score\": [0.0]*((end_date - start_date).days + 1),\n",
    "                \"label\": [\"NEUTRAL\"]*((end_date - start_date).days + 1)\n",
    "            })\n",
    "\n",
    "        # 2️⃣ Fetch Stock Data\n",
    "        stock_df = fetch_intraday_15m(user_ticker, start_date, end_date)\n",
    "        if stock_df.empty:\n",
    "            return render_template(\"index2.html\", error=f\"No 15-min data for {user_ticker}\")\n",
    "\n",
    "        stock_df[\"datetime\"] = pd.to_datetime(stock_df[\"datetime\"]).dt.tz_localize(None)\n",
    "        stock_df[\"date\"] = stock_df[\"datetime\"].dt.date\n",
    "\n",
    "        daily_sent[\"date\"] = pd.to_datetime(daily_sent[\"date\"]).dt.date\n",
    "        merged = pd.merge(stock_df, daily_sent, on=\"date\", how=\"left\")\n",
    "        merged[\"sentiment_score\"].fillna(0.0, inplace=True)\n",
    "        merged[\"label\"].fillna(\"NEUTRAL\", inplace=True)\n",
    "\n",
    "        # 3️⃣ Prophet\n",
    "        prophet_df = merged[[\"datetime\", \"Close\", \"sentiment_score\"]].rename(columns={\"datetime\": \"ds\", \"Close\": \"y\"})\n",
    "        m = Prophet()\n",
    "        m.add_regressor(\"sentiment_score\")\n",
    "        m.fit(prophet_df)\n",
    "\n",
    "        target_ts = requested_dt\n",
    "        last_hist = prophet_df[\"ds\"].max()\n",
    "\n",
    "        if target_ts <= last_hist:\n",
    "            sent_val = daily_sent.loc[daily_sent[\"date\"] == target_ts.date(), \"sentiment_score\"]\n",
    "            target_sent = float(sent_val.iloc[0]) if not sent_val.empty else 0.0\n",
    "            df_pred = pd.DataFrame({\"ds\": [target_ts], \"sentiment_score\": [target_sent]})\n",
    "            pred = m.predict(df_pred)\n",
    "            prophet_price = float(pred[\"yhat\"].iloc[0])\n",
    "        else:\n",
    "            freq = \"15T\"\n",
    "            future_index = pd.date_range(start=last_hist + pd.Timedelta(minutes=15), end=target_ts, freq=freq)\n",
    "            future_df = pd.DataFrame({\"ds\": future_index})\n",
    "            future_df[\"sentiment_score\"] = future_df[\"ds\"].dt.date.map(\n",
    "                lambda d: float(daily_sent.loc[daily_sent[\"date\"] == d, \"sentiment_score\"].iloc[0])\n",
    "                if d in list(daily_sent[\"date\"]) else 0.0\n",
    "            )\n",
    "            pred_future = m.predict(future_df)\n",
    "            prophet_price = float(pred_future[pred_future[\"ds\"] == target_ts][\"yhat\"].iloc[0]) \\\n",
    "                            if target_ts in list(pred_future[\"ds\"]) else float(pred_future[\"yhat\"].iloc[-1])\n",
    "\n",
    "        # 4️⃣ XGBoost\n",
    "        xdf = merged[[\"datetime\", \"Close\", \"sentiment_score\"]].dropna().copy()\n",
    "        xdf[\"day\"] = xdf[\"datetime\"].dt.day\n",
    "        xdf[\"month\"] = xdf[\"datetime\"].dt.month\n",
    "        xdf[\"year\"] = xdf[\"datetime\"].dt.year\n",
    "        xdf[\"hour\"] = xdf[\"datetime\"].dt.hour\n",
    "        xdf[\"minute\"] = xdf[\"datetime\"].dt.minute\n",
    "        xdf[\"dayofweek\"] = xdf[\"datetime\"].dt.dayofweek\n",
    "        X = xdf[[\"day\", \"month\", \"year\", \"hour\", \"minute\", \"dayofweek\", \"sentiment_score\"]].values\n",
    "        y = xdf[\"Close\"].values\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        xgb = XGBRegressor(n_estimators=100, verbosity=0)\n",
    "        xgb.fit(X_scaled, y)\n",
    "\n",
    "        req_dt = requested_dt\n",
    "        req_features = np.array([[req_dt.day, req_dt.month, req_dt.year,\n",
    "                                  req_dt.hour, req_dt.minute, req_dt.dayofweek,\n",
    "                                  float(daily_sent.loc[daily_sent[\"date\"] == req_dt.date(), \"sentiment_score\"].iloc[0])\n",
    "                                  if req_dt.date() in list(daily_sent[\"date\"]) else 0.0]])\n",
    "        req_scaled = scaler.transform(req_features)\n",
    "        xgb_price = float(xgb.predict(req_scaled)[0])\n",
    "\n",
    "        req_label = daily_sent.loc[daily_sent[\"date\"] == req_dt.date(), \"label\"]\n",
    "        label_display = req_label.iloc[0].title() if not req_label.empty else \"Neutral\"\n",
    "\n",
    "        return render_template(\"index2.html\",\n",
    "                               ticker=user_ticker.upper(),\n",
    "                               input_datetime=str(requested_dt),\n",
    "                               prophet_price=round(prophet_price, 4),\n",
    "                               xgb_price=round(xgb_price, 4),\n",
    "                               sentiment_label=label_display)\n",
    "\n",
    "    except Exception as e:\n",
    "        return render_template(\"index2.html\", error=f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n",
    "\"\"\"\n",
    "with open(\"app.py\", \"w\") as file:\n",
    "    file.write(code.strip())\n",
    "\n",
    "print(\"✅ Flask app has been saved as app.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fabda01-11d7-4b2c-96d3-f81847d4a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests: 2.32.5\n",
      "transformers: 4.56.1\n",
      "torch: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import requests, transformers, torch\n",
    "\n",
    "print(\"requests:\", requests.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721fa1da-981d-4c55-9380-adf881581a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ requirements.txt created successfully \n"
     ]
    }
   ],
   "source": [
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"Flask==3.0.0\n",
    "gunicorn==21.2.0\n",
    "vaderSentiment==3.3.2\n",
    "pandas==2.2.2\n",
    "numpy==1.26.4\n",
    "requests==2.32.3\n",
    "prophet==1.1.5\n",
    "xgboost==2.1.1\n",
    "scikit-learn==1.5.2\n",
    "yfinance==0.2.44\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ requirements.txt created successfully \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59668e31-abcf-4254-815c-54c6350fc0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ runtime.txt file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# create_runtime.py\n",
    "with open(\"runtime.txt\", \"w\") as f:\n",
    "    f.write(\"python-3.10.4\")\n",
    "\n",
    "print(\"✅ runtime.txt file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974a4be-23ed-449b-b5c3-ec0deebdae49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
